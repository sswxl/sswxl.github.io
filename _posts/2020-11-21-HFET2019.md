---
\
---

# An Attentive Fine-Grained Entity Typing Model with Latent Type Representation  

* [TOC]
{: toc}

# HFET

## Abstract　

我们提出了一种具有新颖的**注意力机制和混合类型分类器**的细粒度实体类型模型。 我们从两个方面推进现有方法：**特征提取和类型预测**。 为了捕获更丰富的上下文信息，我们采用上下文化的词表示形式，而不是先前工作中使用的固定词嵌入。 另外，我们建议一种两步式的“提及感知”注意机制，使模型能够专注于提及和上下文中的重要单词。我们也提出了一种超越二进制相关性的混合分类模型，以**利用潜在类型表示来利用类型相互依赖性**。与其独立预测每种类型，我们预测了一个可编码潜在类型特征的低维向量，并从该潜在表示中重建了类型向量。

## Introduction

细粒度实体类型通常被表述为多标签分类问题。 先前的方法**[KNET、UFET]**通常以二进制相关性解决该问题，该问题将问题分解为孤立的二进制分类子问题，并独立预测每种类型。 但是，这种方法通常因其**标签独立性假设而受到批评**，这不适用于细粒度的实体键入。 例如，如果模型有信心预测类型艺术家，则应提升其父类型人员，但不鼓励组织及其后代类型。 为了**捕获类型之间的相互依赖关系**，我们提出了一种混合模型，除了二进制相关性(二元关联)之外，该模型还包含潜在类型表示。 具体来说，该模型学习预测低维向量，该向量对通过Principle Label Space Transformation  获得的潜在类型特征进行编码，并从该潜在表示中重建稀疏和高维类型矢量。

细粒度实体类型化的另一个主要挑战是区分相似类型，例如导演和演员，这需要模型捕获文本中的细微差别。 先前的神经模型[NFGEC、UFET、NFGEC]通常**从预训练的词嵌入中提取特征**。 取而代之的是，我们采用上下文化的词表示法，它可以捕获上下文**感知**的词语义，并更好地表示词汇外的词。 我们进一步提出了一种两步注意机制，以主动从句子中提取最相关的信息。 特别是，我们以提及提及的方式计算上下文词的关注度，从而使模型可以针对不同的提及集中于句子的不同部分。



# Experiments

