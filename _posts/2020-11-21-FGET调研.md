---
layout: post
title: FGET总结
mathjax: true
author: Wxl
date: 2020-11-21
header-style: text
excerpt_separator: <!--more-->
---

| models              | Datasets | 特征提取 | 分类模型 | 优点 | 缺点 |
| :------------------ | :------: | :------: | -------- | ---- | ---- |
| AFET2016            |          |          |          |      |      |
| PLE2016             |          |          |          |      |      |
| AAA2017             |          |          |          |      |      |
| NFGEC2017           |          |          |          |      |      |
| KNET2018            |          |          |          |      |      |
| NFETC2018           |          |          |          |      |      |
| NFGEC-LME2018       |          |          |          |      |      |
| UFET2018            |          |          |          |      |      |
| NFETC-CLSC2019      |          |          |          |      |      |
| DenoiseET2019       |          |          |          |      |      |
| HFET2019(attentive) |          |          |          |      |      |
| NFETC-VAT2020       |          |          |          |      |      |
| FGET-RR2020         |          |          |          |      |      |
| NFETC-AR2020        |          |          |          |      |      |
| ACL2020             |          |          |          |      |      |
| NDP2019             |          |          |          |      |      |
| EFGET2019           |          |          |          |      |      |
| IFETET2019          |          |          |          |      |      |

难点：1..

分析文章怎么解决的

缺点（从其他文章补充）

[细粒度实体分类论文综述](https://www.sohu.com/a/399414974_500659)

语料库级的细粒度实体分类  ---句子级的细粒度实体分类  

对于实体类别相关问题，论文的做法是把样本表示和类型表示映射到同一个空间，这样就能通过计算样本和类型语义的相似度来进行分类。对于某个预定义好的实体类型，我们**不能直接用其类型词的词向量去计算语义距离，因为比如 other 标签就很难反映与其他类型的差异。相对可靠的是寻找类型类别对应的典型实体。,用这些典型实体的词向量取平均作为类型嵌入，**

![image-20201124154431849](/assets/fet/image-20201124154431849.png)

![image-20201124154431849](../assets/fet/image-20201124154431849.png)

有三种策略推断真实的𝑦，不同策略的提出是为了处理类型之间的依赖关系。比如不应该同时给一个提及标注位置和人；又比如如果标注
了演员，那么这个提及也应该是表示一个人。 这三种策略如下：  

- 独立推断策略： $𝑝(𝑦\mid𝑥) > 0.5$，就认为𝑥具有𝑦这个类型，如果对于所有 y，$𝑝(𝑦\mid𝑥) ≤ 0.5$，那么取$𝑝(𝑦\mid𝑥)$最大的 y 作为 x 的类型。这种方法主要应用于多分类的设定  Ling 等人[3]，Shimaoka 等人[13]、 Onoe[8]  
- 自上而下搜索策略：这种方法认为每个提及只有一条类型路径，利用$𝑝(𝑦\mid𝑥)$或者非概率形式的打分函数，进行从 root 节点开始往下的搜索，直到$𝑝(𝑦\mid𝑥)$小于某个阈值停止。  
- 单标签分类策略：这种方法将整个问题建模为一个单标签分类问题，认为对于一个提及来说，只有一个类型路径可以描述它在上下文中的意义。该方法将所有的类型用于分类，而只选择$𝑝(𝑦\mid𝑥)$最大的𝑦，然后将𝑦的所有祖先类型也作为预测的结果。 Xu 等人[16]、本文提出的两种方法均采用了这种策略。  

由于独立推断策略**忽略了类型之间的依赖关系**， 一些研究人员希望在模型训练中就考虑到类型依赖问题，他们通常认为𝜃是类型的向量表示，而不仅仅是分类器参数。 **Shimaoka2017**将类型𝑡所在的类型路径上所有父类型的向量与其本身相加作为𝑡的新向量表示。**Attentive2019**提出用奇异值分解去建模标签的潜在语义信息，用样本表示去重构其标签的潜在语义表示。  

# 提及表示

在**提及表示**方面，研究人员还探索了许多不同的方法。 **Abhishek** 等人[31]采用单向长短时记忆网络去编码提及表示， **Xu** 等人[16]在提及表示方面综合采用了Abhishek 等人[31]和 Shimaoka 等人[13]的做法。 **Xiong** [^5 ]等人[24]考虑到对于代词提及来说，其词向量可能不能很好的表示提及，因此利用上下文隐层表示和提及隐层表示去建模提及表示，设计了一种门限机制去权衡上下文和提及本身对样本表示
的影响。 这种方法最初由 Dhingra 等人[32]提出，他们将其应用于阅读理解中的**共指提及**。 **Onoe** 等人[8]为了解决提及中常出现未登陆词并且建模提及的形态学特点，在提及表示的建模中加入了 Char-CNN。

# 上下文表示

在**上下文表示**方面，Xin  等人[34]利用实体的 TransE表示作为注意力机制的查询向量获得了与实体更相关的上下文表示，在他们自建的数据集上取得了一定效果。 Onoe 等人[8]探索了采用 BERT[36]编码上下文的方法。 Zhou [^6]等人[37]则将细粒度实体分类建模为一个匹配问题， 采用预训练的 ELMo 向量直接编码提及所在上下文，通过检索加规则匹配的方法去处理零样本实体分类问题， ELMo 句向量的
编码被应用于句子相似度的计算。 在预训练语言模型的利用这方面还没有很大的进展，这一方向尚有比较大的研究空间。

# 类型向量

在**类型向量θ**方面， 为了处理零样本与少样本的情况， Ma [^7]等人[38]利用类型与实体的共现去寻找类型的典型实体，利用典型实体的词向量作为类型向量。而Yuan [^8]等人[39]则利用类型的名字如 PERSON 的词向量作为类型向量θ。 Onoe 等人[8]则利用类型的 WordNet[40]定义去构造类型向量。  

# 噪声标签数据应用  

噪声标签的产生是由于远程监督对于语料的标注中只考虑知识库而忽视了上下文，因此这种标注错误又称为脱离上下文的噪声（out-of-text noise）。 为了克服脱离上下文的噪声的影响，人们做出了很多的尝试，通常来说分成三种做法：

- **第一种方法忽视噪声**标签的影响，将问题建模为多分类问题，直接用噪声数据去训练模型，结果通常较差； 
- 第二种方法试图**过滤掉带有噪声标签的数据**或者噪声标签，然后再用去噪后的语料训练模型， Gillick 等人[6]通过启发式的规则来过滤噪声标签， Onoe 等人[8]等人通过训练一个神经网络分类器来删除和修正噪声标签，Ren 等人[7]通过知识库的先验知识和基于(PPL)部分标记损失的标签嵌入方法来删除噪声标签，这些方法较为依赖于研究人员的个人经验和数据集的特点而不通用；
-  第三种方法则基于部分标记损失（Partial Label Loss， $\color \red PLL$）来拟合不完美的远程监督数据，希望模型在噪声标签的影响下也具有很好的效果。  ==基本上都是这一种，可以利用噪声数据==
  - 所谓的部分标记损失的基本假设是：对一个带有噪声标签的提及来说， 候选标签(利用远程监督获取  )集合中模型预测的分数最大的那个标签的分数应该大于所有的不在候选集合中的标签，  实际上，也就把这个分数最大的标签作为了真实标签。

![image-20201124161625037](/assets/fet/image-20201124161625037.png)

![image-20201124161625037](../assets/fet/image-20201124161625037.png)

Ren 等人[15]给出了 rank loss 版本的部分标记损失方法， Abhishek 等人[31]利用部分标记损失同时嵌入类型与样本，加入迁移学习，将 BBN 数据集上的结果提高到了 0.733（strict acc）； Xu 等人[16]提出了利用 softmax 作为多分类器情况下的部分标记损失方法，加入层次感知损失将 FIGER 数据集上的结果提高到了0.689（strict acc）。  

然而**基于部分标记损失的方法会严重的受到确认偏差**（Confirmation bias）的影响，所谓的确认偏差（Confirmation bias）就是指模型将自己的预测作为下一步优化的目标所带来的优化目标与实际目标的偏差。根据公式(2.9)，噪声标签中最大的那个类型$\hat y$将会作为模型下一步优化的目标，如果模型开始阶段选对了噪声 标签中的一个，那么后面的优化会持续的使模型选择这个目标（由于模型拟合的目标是减小部分标记损失），但如果模型开始就选错了提及 m 的标签，那么这种确认偏差就会不断的累计，使得模型退化。   

# 数据集

（1） OntoNotes 数据集[6]：该数据集最初由 Weischedel 等人[70]提供， Gillick等人[6]选择了其中的新闻部分作为远程监督细粒度实体分类的数据集，文档共13109 篇，其中 77 篇作为测试集由人工标注， 测试集总计 8963 个提及[16]，包含89种细粒度实体类型，实体类型层级为3层。**Gillick**等人[6]利用DBpedia spotlight[71]对测试集以外的新闻文档进行了远程监督实体链接，得到了带噪声的训练集， 总计 253241 个提及。
（2） BBN 数据集：该数据集最初由 Weischedel 等人[72]标注， 包含 2311 篇华尔街日报的文章，文章共有 48K 句子，包含 47 种实体类型，实体类型层级为 2层。 Since BBN corpus is **==fully annotated==**,   **Ren** 等人[15]利用远程监督对该语料库的训练集进行了标注， 得到了 86078 个训练集提及。人工标注的测试集提及数量则为 12845 个。两个数据集的明细如表 3-1 所示。 **从表中可以发现，实际上测试集大部分提及都是 clean data，这与本章采用 2.1.2 节所述的单标签多分类推断策略是一致的**，本章认为一个提及在上下文仅有一个类型路径可以描述它。  

| Data sets               | Wiki    | OntoNotes | BBN     |
| ----------------------- | ------- | --------- | ------- |
| \#Types                 | 113     | 89        | 47      |
| \#Documents             | 780,549 | 13,109    | 2,311   |
| \#Sentences             | 1.51M   | 143,709   | 48,899  |
| \#Training mentions     | 2.69M   | 223,342   | 109,090 |
| \#Ground-truth mentions | 563     | 9,604     | 121,001 |
| \#Features              | 644,860 | 215,642   | 125,637 |
| \#Edges in graph        | 87M     | 5.9M      | 2.9M    |

| Data sets                     | Wiki/FIGER | BBN     |
| ----------------------------- | ---------- | ------- |
| types                         | 128        | 56      |
| mentions-train                | 4932861    | 4695889 |
| mentions-test                 | 563        | 13282   |
| EL-train-types in true labels | 93.51%     | 93.98%  |
| EL-test-types in true labels  | 49.73%     | 64.03%  |

train_link_cnt= begin
train_len= begin 4932861
100%|██████████| 100000/100000 [3:05:42<00:00,  8.97it/s]
train_link_cnt=  0.93511
dev_link_cnt= begin
dev_link_cnt=  0.9395
test_link_cnt= begin
test_link_cnt=  0.49733570159857904
21-01-13 17:48:07 data_statistics_figer.py:146 INFO - dataset=figer   train_link_cnt=0.93511
21-01-13 17:48:07 data_statistics_figer.py:147 INFO - dataset=figer   train_count=4932861
21-01-13 17:48:07 data_statistics_figer.py:148 INFO - dataset=figer   dev_link_cnt=0.9395
21-01-13 17:48:07 data_statistics_figer.py:149 INFO - dataset=figer   dev_count=2000
21-01-13 17:48:07 data_statistics_figer.py:150 INFO - dataset=figer   test_link_cnt=0.49733570159857904
21-01-13 17:48:07 data_statistics_figer.py:151 INFO - dataset=figer   test_count=563

train_link_cnt= begin
train_len= begin 4695889
100%|█████████████████████████████████| 100000/100000 [2:48:19<00:00,  9.90it/s]
train_link_cnt=  0.93975
dev_link_cnt= begin
dev_link_cnt=  0.949
test_link_cnt= begin
test_link_cnt=  0.6403403101942479
21-01-13 17:41:22 data_statistics_bbn.py:147 INFO - dataset=bbn   train_link_cnt=0.93975
21-01-13 17:41:22 data_statistics_bbn.py:148 INFO - dataset=bbn   train_count=4695889
21-01-13 17:41:22 data_statistics_bbn.py:149 INFO - dataset=bbn   dev_link_cnt=0.949
21-01-13 17:41:22 data_statistics_bbn.py:150 INFO - dataset=bbn   dev_count=2000
21-01-13 17:41:22 data_statistics_bbn.py:151 INFO - dataset=bbn   test_link_cnt=0.6403403101942479
21-01-13 17:41:22 data_statistics_bbn.py:152 INFO - dataset=bbn   test_count=13282

![image-20201124162224880](/assets/fet/image-20201124162224880.png)

<img src="../assets/fet/image-20201124162224880.png" alt="image-20201124162224880" style="zoom: 50%;" />

为了公平比较， 本章**使用 Xu 等人[16]预处理过的 OntoNotes 数据集与 Abhishek等人[31]提供的 BBN 数据集**。为了调试超参数， 本章按照其他同类文章相同的做法，从测试集中随机抽样 10%的数据作为开发集， 用剩余的数据作测试集。  

针对训练语料难以获取的问题， Ling 等人[3]提出了利用远程监督（ Distant Supervision， DS） [9]来获取细粒度实体分类的训练数据的方法，并构造了 **FIGER** 数据集， Gillick 等人[6]则用类似的方法标注了 **OntoNotes** 数据集， Ren 等人[15]为 学术界进一步提供了 **BBN** 数据集， Choi 等人[18]同样利用远程监督方法构造了迄 今为止最大的细粒度实体分类数据集 **UFET**。    

# 问题

什么是候选标签

# Ling 

Ling[^3] 等人最早提出采用远程监督来构建细粒度实体分类数据集 FIGER。  Ling 等人[3]在 FIGER 数据集上构造了十种特征用于提及的样本表示。多标签多分类问题 $𝑦 ∈ R_{|T|}  $  ,

# Dong-HNM 

Dong [^1]最早开始利**用神经网络去建模提及与其上下文的表示**  

他们的模型中将样本表示分为上下文表示、 提及表示，将两个表示拼接起来作为一个softmax 分类器[11]的输入。

词汇的表示采用 Turian 等人[28]预训练的词向量。在词向量的基础上，利用多层感知机去建模上下文表示，利用循环神经网络 Elman 网
络[29]去提取提及表示。  

# Gillick-FIGER/HYENA-Min  

Gillick[^2] 等人提出了**上下文依赖**的细粒度实体分类任务 。Gillick 等人[6]在 OntoNotes 数据集上加入了一些独有特征包括提及核心词的前三个字母、 自上而下搜索策略

**最初的工作假设一个实体提及的训练数据集中存在的所有标签都是正确的**，但Gillick et al. (2014) **引入了上下文相关**的FETC，并提出了一组修剪标签的启发式方法，这些标签在实体提及当地情况的情况下可能不相关。

# AFET2016

单标签多分类问题  $𝑦 ∈ R_{1×|T|}  $基于假设： 只有一条类型路径符合提及在上下文的意义 。自上而下搜索策略

 Ren 等人[15]首先提出利用部分标记损失来解决远程监督带的噪声标签问题，并且构建了 BBN 数据集；

AFET对干净和嘈杂的实体提及区分损失函数。AFET在其参数损失函数（模型参数$\alpha $）中使用通过给定数据获得的label-label 相关信息。 在推理期间，**AFET使用阈值将正类型与负类型分开**（相似性阈值参数$d$）。 但是，**AFET的损耗函数对参数的变化很敏感**

our method considers type hierarchy and correlation  

# PLE2016

自上而下搜索策略

PLE+HYENA/FIGER 方法： Ren 等人[7]在 AFET 的基础上进一步提出利用部分标记损失训练类型与提及的嵌入来去除标签噪声，然后利用去除噪声标签之后的数据进行训练，训练使用的模型是 HYENA[73]和 FIGER  

has tackled the problem of label noise in fine-grained entity typing, but focused on how to generate a clean training set instead of doing entity typing  

# Attentive2016

独立推断策略

Shimaoka 等人[13]首先利用自注意力机制对提及上下文建模，在他们的工作中，并没有区分噪声样本与干净样本，而假设训练集都
是正确的标签，将问题设置为简单的多分类问题，**后续模型的特征抽取器架构大多延续 Attentive 方法**；

提出了一个带注意力的神经网络模型，该模型**使用LSTM编码实体提及的上下文**的内容，并使用一种注意力机制使该模型专注于实体提及上下文中的相关表达。 但是，**该模型假定通过远程监管获得的所有标签都是正确**的。

# NFGEC2017

在上下文表示的编码上采用了循环神经网络加自注意力机制的方法，为后期的研究打下了重要基础 。并利用远程监督构建了 OntoNotes 数据集。之后，许多工作开始研究噪声数据的应用问题 。

Shimaoka 等人[13,14]在上下文表示的建模上采用了长短时记忆网络，然后利用自注意力机制（self attention mechanism） 来融合得到整个文本片段的特征表示，使得模型更加关注与分类相关的词汇片段。在提及表示上则采用了提及所有词向量的平均。 

**For evaluation**, in our experiments we use the two well-established **manually annotated**
**datasets** FIGER (GOLD) and OntoNotes, where like Gillick et al. (2014), we discarded pronominal mentions, resulting in a total of 8, 963 mentions. 

**For training,** we use the automatically ind                                                                        uced publicly available datasets provided by Ren et al. (2016). Ren et al. (2016) aimed to eliminate label noise generated in the process of distant supervision and we use the “raw” noisy data2 provided by them for training our models  

# AAA2017

 Abhishek 等人[31]提出了部分标记损失的多分类版本；

自上而下搜索

# KNET2018



# NFETC2018

**完全用的NFGEC2017的数据**

单标签多分类问题\单标签分类策略：

加入了层次感知损失（hierarchy aware loss）以解决 over-specific-noise 的问题，采用 PLL 方法的𝑠𝑜𝑓𝑡𝑚𝑎𝑥版本来解决 out-of-text-noise 的问题

把祖先类型也当成是部分正确的标签，加入优化，只是按照一定的比例折损。**这样其实也存在一个问题，就是即便是没有over-specific noise的data也会加上一个错误的标签。**

- 加入noise data （r相对f）模型未必有提高
- 加入层次感知损失有很大的提高：但其实这个和dataset关系比较大，如果测试集倾向于标注叶节点，这个方法可能会带来一些损失。

# NFGEC-LME2018

探索了利用实体的知识库属性给实体进行细粒度实体分类的方法  

# UFET2018

# NFETC-CLSC2019

单标签多分类问题.。单标签分类策略：CLSC是无参的。

# DenoiseET2019

训练模型筛选噪声样本 ,独立推断策略

# HFET2019(attentive)

# NFETC-VAT2020

结合预训练语言模型 BERT 在 OntoNotes 上达到了当前最高水平  

# FGET-RR2020

# NFETC-AR2020

# ACL2020

# NDP2019

# EFGET2019

# IFETET2019

多类别多标签的分类

| models              | Datasets | 特征提取 | 分类模型 | 优点 | 缺点 |
| :------------------ | :------: | :------: | -------- | ---- | ---- |
| AFET2016            |          |          |          |      |      |
| PLE2016             |          |          |          |      |      |
| AAA2017             |          |          |          |      |      |
| NFGEC2017           |          |          |          |      |      |
| KNET2018            |          |          |          |      |      |
| NFETC2018           |          |          |          |      |      |
| NFGEC-LME2018       |          |          |          |      |      |
| UFET2018            |          |          |          |      |      |
| NFETC-CLSC2019      |          |          |          |      |      |
| DenoiseET2019       |          |          |          |      |      |
| HFET2019(attentive) |          |          |          |      |      |
| NFETC-VAT2020       |          |          |          |      |      |
| FGET-RR2020         |          |          |          |      |      |
| NFETC-AR2020        |          |          |          |      |      |
| ACL2020             |          |          |          |      |      |
| NDP2019             |          |          |          |      |      |
| EFGET2019           |          |          |          |      |      |
| IFETET2019          |          |          |          |      |      |

- BBN 数据集上，测试集上的/FAC和训练集上的/FACILITY 是一个标签，遗憾的是，似乎是处理上的疏漏，这两者并没有统一起来：基于任老师原版数据的话这部分数据（大约400个提及）应该是会直接标错的，然后还有一部分提及是重复的，可能是300个左右；而之前在该数据集上的SOTA[[7\]](https://zhuanlan.zhihu.com/p/108914989#ref_7)由于没有发现这个问题，在代码上的原因，直接错误的将这部分数据删除了，也进行了去重。然后[这篇文章](https://link.zhihu.com/?target=https%3A//github.com/wujsAct/fine-grained-entity-typing-Hier-Denoise)应该是目前直接全部采用任老师数据集的比较新的文章。

- FIGER数据集上存在两个版本的类型树，尽管可以一一对应，但对结果会产生巨大影响，相关的讨论应该在Xu等人[[5\]](https://zhuanlan.zhihu.com/p/108914989#ref_5)、Shimaoka等人[[8\]](https://zhuanlan.zhihu.com/p/108914989#ref_8)的文章中找到。值得注意的是，应该是Shimaoka等人提到之前的文章对于FIGER的训练集实际上自己进行了划分，他们不能确定大家的训练集是否是一样的。由于FIGER这个数据集训练集过大，测试集则只有500个样本，实际上测试结果的随机性还蛮大的，印象中不是所有的label都在测试集中出现了。

- OntoNotes数据集除了[[9\]](https://zhuanlan.zhihu.com/p/108914989#ref_9)，目前应该都采用了Gillick等人[[10\]](https://zhuanlan.zhihu.com/p/108914989#ref_10)去除了代词提及的版本，包括2019年的几篇文章，其实就深度学习而言，代词提及实际上是能做的比较好的（在指代消解的一些实验中有所说明[[11\]](https://zhuanlan.zhihu.com/p/108914989#ref_11)），为什么采用这个版本的数据，大概是历史原因了。

# References

[^1]: Dong : A hybrid neural model for type classification of entity mentions[C],\2015.  
[^2]: Gillick D, Context-dependent fine-grained entity type tagging[J]. arXiv , 2014  
[^3]: Ling  Fine-grained entity recognition[C]. Twenty-Sixth AAAI 2012  
[^4]: Shimaoka. An Attentive Neural Architecture for Finegrained Entity Type Classification[C]. 2016:
[^5]: Xiong . Imposing Label-Relational Inductive Bias for Extremely Fine-Grained Entity Typing[J]  2019
[^6]: Zhou . Zero-Shot Open Entity Typing as Type Compatible Grounding[C]. , 2018:
[^7]: Ma . Label embedding for zero-shot fine-grained named entity typing[C]. COLING 2016
[^8]: [39] Yuan Otyper: A neural architecture for open named entity typing[C]., 2018.

