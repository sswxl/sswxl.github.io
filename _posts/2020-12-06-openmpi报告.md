[Introduction to Parallel Computing Tutorial]()

## 什么是分布式系统？

在最简单的定义中，分布式系统是一组计算机，这些计算机一起工作，对于最终用户而言，它们就像一台计算机。

这些机器具有**共享状态，可以同时运行，并且可以独立发生故障**，而不会影响整个系统的正常运行时间。

There are two basic tasks that any computer system needs to accomplish:

- storage and
- computation

并行计算机可以简单分为**共享内存和分布式内存**，

通信是指线程之间以何种机制来交换信息，在命令式编程中，线程之间的通信机制有两种：

- 共享内存
- 消息传递

在共享内存的**分布式系统**并发模型里，线程之间共享程序的公共状态，**线程之间通过写-读内存中的公共状态来隐式进行通信。**

在消息传递的**分布式系统**并发模型里，线程之间没有公共状态，**线程之间必须通过明确的发送消息来显式进行通信。**

共享内存计算是指将一个程序的任务分割成多个较小的、可在一个节点内并行运行的工作单元，即线程。这些线程共享了对某一部分内存的访问，故称之为*共享内存计算*。与之相比，*分布式内存计算* 的并行过程是通过多个进程（执行多线程）来完成的；每个进程都拥有各自的内存空间，其他进程无法访问。在*分布式内存* 方法中，这些进程分布在多台计算机、多个处理器和/或多个内核中，共同组成了一个并行程序。

简而言之，内存不再是共享的，而是被分配给各个进程

要理解分布式计算的设计意图，我们先来了解***集群计算*** 这一基本概念。一台计算机的内存和计算能力是有限的。为了提升性能及增加可用的内存量，科学家开始将几台计算机连接在一起，组成了所谓的*计算机集群*。

**拆分问题**

通过计算机集群来分配物理进程，这种方法将并行问题的复杂度提升到了一个新水平。每个问题都要分割成更小的单元——不仅数据需要拆分，对应的任务也要分配给各台机器。以矩阵类的问题为例，在执行庞大的阵列运算时，阵列可以拆分成区块（可能是不连续的，也可能是重叠的），每个私有区块由一个进程专门负责。当然，每个区块上的运算和数据可以和其他区块上的运算和数据相互耦合，所以**在进程之间引入通信机制成为了必要。**

为了实现通信，其他进程需要的数据或信息会被收集成数据块，然后通过发送消息与其他进程交换数据。这种方法被称为*消息传递*，模式可以是全局交换（多对多、多对一、一对多）或点对点交换（一个点发送进程，一个点接收进程）。根据整个问题的耦合程度，消息交换可能需要大量的通信。

人们希望尽可能在本地处理数据和执行运算，目的是尽量减少通信量。

 

使用分布式内存的另一个好处是，每向集群中添加一个计算节点，我们就会得到更多可用内存。这意味着我们不再受限于主板分配的内存空间，因此理论上可以计算任意大的模型。在多数情况下，分布式内存计算的扩展性强于共享内存计算

# 共享内存

线程之间通过写-读内存中的公共状态来隐式进行通信

在当前的并行机子中，openMP和openMPI都是需要的（从上面的各自概念可以看出），openMP用于本地的并行计算（共享内存内存架构），支持目前所有平台上的c,fortran等的共享内存式并行计算，它相当于是给出了一个让并行编程更加容易实现的模型，

OpenMP 通过完全使用线程来实现并行

共享内存的编程模型，线程通信主要通过共享内存变量。

也是因为共享变量可能会导致数据竞争，循环依赖等

**所有处理器/内核都访问共享的主内存。**

OpenMP中的并行化**使用多个线程**

在共享内存计算系统中，整个程序的各个分布进程并行运行，共享相同的内存空间。这种方式保证了数据在核心和处理器之间高速传输，但主要缺点是共享内存节点上的计算资源有限。如果问题规模扩大，或者需要引入更多核心来减轻每个核心的计算量，人们却不能增加更多资源。综上所述，共享内存计算的*扩展性* 较差。

# 分布式内存

线程之间必须通过明确的发送消息来显式进行通信。

每个独立的处理器（processor）都有独立私有的内存，通过互联网络连接起来的分布式内存系统，利用消息传递来编程的模型。

而openMPI则是用于机器之间的通信（分布式内存架构）。

​	**分布式计算**是研究分布式系统的[计算机科学](https://en.wikipedia.org/wiki/Computer_science)领域。甲*分布式系统*是一种系统，其组件位于不同的[联网计算机上](https://en.wikipedia.org/wiki/Computer_network)，该通信并通过协调它们的行动[传递消息](https://en.wikipedia.org/wiki/Message_passing)到彼此。这些组件相互交互以实现一个共同的目标。

在分布式系统中运行的[计算机程序](https://en.wikipedia.org/wiki/Computer_program)称为**分布式程序**。[[2\]](https://en.wikipedia.org/wiki/Distributed_computing#cite_note-2)消息传递机制有许多不同类型的实现，

*分布式计算*还指使用分布式系统来解决计算问题。在*分布式计算中*，一个问题被分为许多任务，每个任务都由一台或多台计算机解决，ht这些计算机通过消息传递相互通信。

在消息传递模型中，程序通过明显的消息传递使共享数据可供使用。换句话说，程序员需要意识到进程之间数据移动。程序员不得不明显地使用通讯原语（例如SEND和RECEIVE），放一个重要的负担在它们身上。

相反，分布式共享内存系统隐藏这个明显的数据移动并且提供一个较简单的程序员已经精通的共享数据抽象。因此，利用分布式共享内存比通过明显的消息传递更容易地设计和编写并行算法**。**

**在消息传递模型中，数据在两个不同的地址空间之间移动。这使得它难以在两个进程之间传递复杂的数据结构。**而且传递由“引用”的数据和传递包含指针的数据结构一般是困难的和贵的。相反，分布式共享内存系统允许传递由“引用”的复杂的数据结构，于是简化了对分布式应用的算法的开发。

在分布式内存计算系统中，内存是由多个并行进程分配的，而非共享的。这些进程必须通过发“消息”进行显式通信，所以通信和同步会耗费额外的时间。我们应该利用数据局部性，并改善算法，尽可能地减少通信量。分布式内存计算的一大优势是出色的扩展性，轻松支持增加更多可用的资源（节点，核心与内存资源）。



在世界超级计算机 500 强中，大多数集群计算节点上的每个插槽均安装了八核处理器。小型和中型计算集群也采用了相似的装置。这种配置的广泛应用使得混合运用两种机制成为必然：共享内存应用于节点内计算，同时分布式内存应用于节点间计算。这种做法的目标是最大限度地提升扩展性，并减少消息传输的成本，同时充分发挥共享内存的优势。*混合并行计算* 结合了共享内存机制和分布式内存机制，提供了一种灵活适应所有计算平台的通用方法。如果正确地结合两种并行技术，就可以加快计算速度，提高扩展性，并且高效地利用硬件。

分布式系统

- 共享内存
- 消息传递

分布式计算

- mapereduce

分布式存储

- hdfs

并行计算

高性能计算

- 

共享内存就是多个核心共享一个内存，目前的PC就是这类（不管是只有一个多核CPU还是可以插多个CPU，它们都有多个核心和一个内存），一般的大型计算机结合分布式内存和共享内存结构，即每个计算节点内是共享内存，节点间是分布式内存。想要在这些并行计算机上获得较好的性能，进行并行编程是必要条件。目前流行的并行程序设计方法是，分布式内存结构上使用MPI，共享内存结构上使用Pthreads或OpenMP。共享内存并行计算机，编辑这篇文章的机器就属于此类型（普通的台式机）。只要求对线程之间关系进行最基本控制（同步，互斥等）的我们来说，OpenMP再适合不过了。

# MPI 

MPI 中的关键编程接口

- MPI_Init（int*argc,char***argv）:函数，初始化
- MPI_Finalize（）：函数，结束时释放资源
- MPI_Comm_size：变量，定义 processes 的个数
- MPI_Comm_rank：变量，定义当前进程的序号
- MPI_Send（）：函数
- MPI_Recv（）：函数
- 一般以“MPI_”为前缀
- **相关进程形成进程组**

- A communicator defines a communication domain - a set of processes that are allowed to communicate with each other
  通信子定义了一个通信域-**允许彼此通信的一组进程。**
- Information about communication domains is stored in variables of type MPI_Comm
  有关通信域的信息存储在 MPI_Comm 类型的变量中
- Communicators are used as arguments to all message transfer MPI routines
  通信子被用作所有消息传输 MPI 例程的参数。
- A process can belong to many different (possibly overlapping) communication domains
  一个进程可以属于许多不同的（可能重叠的）通信域
- MPI defines a default communicator called MPI_COMM_WORLD which includes all the processes
  MPI 定义了一个名为 MPI_COMM_WORLD 的默认通讯子，其中包括所有进程

**MPI 中解决死锁的方式有哪些？**

> 1. 重排代码，避免死锁。
> 2. 在发送时，添加**接收缓冲区**。
> 3. 将**自己（发送端）的地址空间**作为发送缓冲区。
> 4. 使用非阻塞的 send/receive 方法。



## 概念[[编辑](https://en.wikipedia.org/w/index.php?title=Message_Passing_Interface&action=edit&section=4)]

MPI提供了广泛的功能。以下概念有助于理解所有功能并为其提供上下文，并帮助程序员决定在其应用程序中使用哪些功能。MPI的八个基本概念中的四个是MPI-2独有的。

### 传播者[[编辑](https://en.wikipedia.org/w/index.php?title=Message_Passing_Interface&action=edit&section=5)]

Communicator对象连接MPI会话中的进程组。每个通信器为每个包含的进程提供一个独立的标识符，并将其包含的进程按有序[拓扑](https://en.wikipedia.org/wiki/Topology_(disambiguation))进行排列。MPI也具有显式组，但是这些组主要适合于在制作另一个通信器之前组织和重新组织过程组。MPI了解单组内部通信器操作以及双边内部通信器通信。在MPI-1中，单组操作最为普遍。[双边](https://en.wikipedia.org/wiki/Bilateral_synchronization)业务大多出现在MPI-2中，其中包括集体沟通和动态的过程中管理。

可以使用几个MPI命令对通信器进行分区。这些命令包括`MPI_COMM_SPLIT`，其中每个进程通过声明自己具有该颜色来加入几个彩色子通信器之一。

### 点对点基础知识[[编辑](https://en.wikipedia.org/w/index.php?title=Message_Passing_Interface&action=edit&section=6)]

MPI的许多重要功能涉及两个特定过程之间的通信。一个流行的示例是`MPI_Send`，它允许一个指定的进程将消息发送到第二个指定的进程。所谓的点对点操作在模式化或不规则通信中特别有用，例如，[数据并行](https://en.wikipedia.org/wiki/Data_parallelism)体系结构，其中每个处理器在计算步骤之间定期与特定其他处理器交换数据区域，或者[主设备从属](https://en.wikipedia.org/wiki/Master-slave_(technology))体系结构，在该体系结构中，只要先前的任务完成，主服务器就会向[从属](https://en.wikipedia.org/wiki/Master-slave_(technology))服务器发送新的任务数据。

MPI-1指定了用于[阻塞](https://en.wikipedia.org/wiki/Blocking_(computing))和非阻塞点对点通信机制的机制，以及所谓的“就绪发送”机制，通过该机制，仅当已发出匹配的接收请求时，才可以发出发送请求。

### 集体基础[[编辑](https://en.wikipedia.org/w/index.php?title=Message_Passing_Interface&action=edit&section=7)]

[集体功能](https://en.wikipedia.org/wiki/Collective_operation)涉及流程组中所有流程之间的通信（这可能意味着整个流程池或程序定义的子集）。典型的功能是`MPI_Bcast`调用（“[广播](https://en.wikipedia.org/wiki/Broadcasting_(computing))”的缩写）。此功能从一个节点获取数据，并将其发送到流程组中的所有流程。反向操作是`MPI_Reduce`调用，它从组中的所有进程中获取数据，执行一个操作（例如求和），并将结果存储在一个节点上。`MPI_Reduce`通常在大型分布式计算的开始或结束时有用，在这种情况下，每个处理器对一部分数据进行操作，然后将其组合为结果。

# Open MPI

Open MPI [GFB + 04]是消息传递接口（MPI）标准的开源软件实现。在了解MPI的体系结构和内幕之前，必须先讨论MPI标准的一些背景知识。

消息传递接口（MPI）
MPI标准是由MPI论坛创建和维护的，MPI论坛是一个开放团体，由来自行业和学术界的并行计算专家组成。 MPI定义了一种API，该API用于特定类型的便携式高性能进程间通信（IPC）：消息传递。具体来说，MPI文档描述了MPI流程之间可靠的离散类型消息传递。尽管“ MPI进程”的定义要在给定平台上进行解释，但它通常对应于操作系统的进程概念（例如POSIX进程）。 MPI专门用于实现为中间件，这意味着高层应用程序调用MPI函数来执行消息传递。

MPI定义了一个高级API，这意味着它抽象了实际上用于在进程之间传递消息的任何底层传输。这个想法是，发送进程X可以有效地说“采用此数组的1,073个双精度值并将它们发送给进程Y”。相应的接收进程Y有效地表示“从进程X接收一个1,073个双精度值的数组”。发生奇迹了，由1,073个双精度值组成的数组到达Y的等待缓冲区。

**Open MPI诞生了。它的第一次Subversion提交是在2003年11月22日。**











